\def\mytitle{Whirlwind: Overload protection, fault--tolerance and self--tuning in an Internet services platform}
\def\myauthor{Peter Donald, Samar Singh,  Somnath Ghosh}
\def\mykeywords{concurrency, software architecture, overload, fault-tolerance, self-tuning}

\documentclass[conference,a4paper,final]{IEEEtran}

\usepackage{cite}
\usepackage[pdftex]{graphicx,hyperref}
\usepackage{url}
\usepackage{epstopdf}
\usepackage[tight,footnotesize]{subfigure}


\pdfinfo{/Title (\mytitle) 
         /Author (\myauthor)
         /Keywords (\mykeywords)}

\begin{document}

\title{\mytitle}

\author{\IEEEauthorblockN{\myauthor}
\IEEEauthorblockA{\textit{School of Computer Science and Electronic Engineering, La Trobe University,}\\
\textit{Melbourne, Australia}\\
\small \tt peter@realityforge.org, S.Singh@latrobe.edu.au, S.Ghosh@latrobe.edu.au}
}

\def\IEEEkeywordsname{Keywords}

\maketitle

\begin{abstract}
Performance and availability are of critical importance when Internet services are integrated into emergency response management. Poor performance or service failure can result in severe economic, social or environmental cost. This paper presents Whirlwind, a software architecture that includes primitives for overload management and fault tolerance. A Whirlwind service is composed of a collection of isolated, independent, sequential processes that communicate through asynchronous message passing. If a process fails, the fault is contained within the process and a message is propagated to monitoring processes that may attempt to recover from the error. Processes are grouped with other processes that share similar resource, computation and concurrency requirements. Each group contains a scheduler and a thread pool that drives execution of processes within the group. The group may also define a message predicate that determines if a message posted to a process in the group is accepted. A rejected message typically signals overload and allows the application the chance to perform load shedding and avoid overcommitment of resources. Principals are shared between processes in different groups, enabling consistent prioritization and admission control across groups. The resource management policies are typically driven by feedback loops that monitor resource availability and system performance, and adjust tuning parameters to meet performance goals. Whirlwind evolved over a period of five fire seasons as part of emergency response software in Victoria, Australia.
\end{abstract}

\begin{keywords}
\mykeywords
\end{keywords}

\IEEEpeerreviewmaketitle

\section{Introduction}

Whirlwind was born out of the need to create a reliable, scalable software architecture for the Incident Resource Information System (IRIS). IRIS tracks the dispatch and deployment of resources during an emergency response. The resources include everything from vehicles to personnel and the emergency situations have included wildfires, floods and virus outbreaks. IRIS is also responsible for generating the payments for personnel during emergency situations.

Internet traffic is bursty and popular Internet services are likely to be subject to periods of transient or sustained overload. This is intensified for Internet services used in emergency responses. Overload can be caused by unexpectedly high request rates or unexpected shifts in the characteristics of the request distribution. In IRIS the request rate increases dramatically during shift change over times or prior to payment cut--off dates. The characteristics of the requests also changed dramatically depending on whether the users were primarily interacting with the payment subsystem or the resource tracking subsystem.

During periods of overload, many services suffer from response time spikes, throughput loss, unpredictable behavior and crashing. During the February 2009 Victorian bushfires, the number of concurrent users was 5x greater than during previous emergencies. In IRIS, the load grows exponentially with respect to the number of concurrent users and this resulted in a rapid, dramatic, unanticipated increase in system load. Over--provisioning the service can only alleviate the pressure, not avoid the overload problem altogether. 
 
Whirlwind is based on the actor model of concurrency. It incorporates existing work on load management, fault--tolerance, scheduling and self--tuning and synthesizes these elements into a consistent framework. Whirlwind was developed for the Java Virtual Machine (JVM), primarily targeting the Java programming language. The architecture needed to take advantage of the increased number of processing units in modern hardware.

Each iteration of Whirlwind has undergone an extensive performance evaluation before being rolled out into production. Space does not permit presenting a a detailed performance report. Suffice to say that Whirlwind, at least in certain configurations, met the original performance goals and compares favorably with other popular production frameworks.

\section{Background Material}

Past research has focused on parts of the problem but there has been no attempt to bring all the elements together in one consistent framework. A single platform makes it possible to compare the techniques in various combinations and configurations and isolate variation due to environmental factors.

\subsection{Load Management}

Previous work on load management has focused on using techniques such as admission control~\cite{Voigt:2001qe,Cherkasova:2002yb,srinivas00webk,Kanodia:2000qv,welsh03Adaptive,Elnikety:2004ty}, service degradation~\cite{welsh03Adaptive,abdelzaher99web} and scheduling policies~\cite{Zhou06RequestAware,Behren03Capriccio,Schroeder06Overload,Crovella99Alpha,Cherkasova1998Strategy,Larus:2002:Cohort} to limit response time spikes and maintain throughput during periods of overload. Admission control rejects a subset of requests so that the remaining requests meet response time goals. Service degradation aims to deliver less resource intensive content during periods of overload. The assumption is that it is better to deliver some content on time rather than fail to deliver the full content on time, or at all. Scheduling policies determine the order in which requests are accepted and after they have been accepted, the policy for sharing the available processor resources.

Load shedding is typically achieved by selectively applying the above techniques to different requests. Requests can be categorized by low level connection properties~\cite{Voigt:2001qe}, protocol specific parameters (i.e. the url, headers or session associated with a HTTP request)~\cite{Cherkasova:2002yb,Voigt:2001qe} or application specific metrics (i.e. revenue and profits~\cite{Menasec:2000ty}, or \emph{Premium} vs \emph{Basic} users). Requests can also be categorized according to the expected change in resource availability after processing the request~\cite{Behren03Capriccio} or the predicted resource cost to process the request~\cite{Crovella99Alpha}. Other systems categorize the request based on the estimated utility\cite{Zhou06RequestAware} or ability to meet performance goals (i.e. the 90th--percentile of response time~\cite{welsh03Adaptive}). Class--based differentiation is a commonly used coarse--grain classification scheme but fine--grain classification schemes are also popular.

Past research has tended to focus on one categorization axis rather than categorizing a request along multiple dimensions. It is probable that this is done as it makes the mapping between a categorization and a priority simple; \emph{Premium} users are always prioritized above \emph{Basic} users, \emph{Buy} requests are always prioritized above \emph{Browse} requests, while during overload light--weight requests are always prioritized above heavy--weight requests etc. 

\subsection{Fault Tolerance}

A fault tolerant system is one able to recover from errors and restore normal operation. If there is a decrease in service quality, the degradation is proportional to the severity of the fault. Fault tolerance is achieved by expecting faults and designing the system so that it behaves reasonably in the presence of faults.

Erlang is a software architecture designed to survive software and hardware faults~\cite{Armstrong03Thesis} and incorporates these strategies. Erlang models the world as a set of isolated processes. When a process terminates either normally or due to failure, a message is sent to all monitoring processes. The monitoring processes can then take action to recover from the error if required.

An Erlang supervisor is a process that monitors child processes. If a child process fails, the supervisor uses a \emph{restart strategy} to restart the process and if unable to restart the process will terminate itself. Supervisors can monitor other supervisor processes and supervision is typically organized into a tree structure. To ensure that the system can always resume normal operation the root supervisor must be reliable. Erlang's supervisors were part of the architectural design that lead to 99.9999999\% (9 nines) reliability rating (or 31 ms. downtime a year!) of the AXD301 switch~\cite{armstrong:02:COP}.

\subsection{Software Architectures}

Hyper--threading, multi--core and multi--cpu architectures are the direction of current hardware design now that traditional methods of increasing processor performance are no longer providing significant jumps in speed~\cite{Sutter05Concurrency}. This trend towards distribution posses challenges to the multi--threaded, shared memory model utilized by several mainstream software architectures.

The looming multi--core future and the success of Erlang~\cite{Nystrom:03:Telco,armstrong96erlang} has recently placed the actor model in the spotlight. The actor model of concurrency offers an alternative to shared memory architectures. Actors are isolated and independent sequential entities that communicate by passing messages. Typically the number of actors present in a system is an order of magnitude greater than the number of threads supported.

Erlang code is executed by a specialized runtime. However other actor implementations (i.e. ~\cite{Varela:SALSA,Haller:07:ScalaActors,Srinivasan:08:Kilim}) target a general purpose virtual machine such as the JVM. These implementations use the type system or code modification techniques to verify that the actors conform to certain rules (i.e. no access to shared memory) and to integrate the actors with a runtime library. The runtime library provides execution environment for the actors and maps the actors to threads using the 1--to--1 model~\cite{Varela:SALSA}, M--to--N model~\cite{Srinivasan:08:Kilim,Nystrom:03:Telco,armstrong96erlang} or a combination of both approaches~\cite{Haller:07:ScalaActors}.

\subsection{Self-Tuning}

Another challenge facing Internet services is the complexity of tuning the systems. Administrators are expected to translate high--level objectives into low level resource limits and allocations (i.e. the number of worker threads servicing requests). Static limits and allocations rarely ensure the resources are efficiently utilized due to the complex, dynamic relationship between request loads, request distributions and resource availability. 

Self--tuning systems have been proposed as a solution to this problem~\cite{Kephart03AutonomicVision}. In self--tuning systems, feedback loops observe the performance characteristics of a subsystem and adjust the tuning parameters to keep the subsystem operating within the ideal operating range~\cite{welsh03Adaptive,Heiss:91:AdaptiveLoadControl}.

\section{Whirlwind}

Whirlwind is a software architecture based on the actor model of concurrency and implemented on the JVM. The service logic is defined by a collection of isolated, sequential processes that communicate through asynchronous message passing. If a process fails, the fault is contained within the process and a message is propagated to monitoring processes that may attempt to recover from the error.

Processes with similar resource, computational and concurrency requirements are organized into a group. Processes within a group share a message predicate, a worker thread pool and a scheduler. Message predicates make it possible to selectively reject a message posted to a process in the group. Message predicates are a form of per--group admission control. The worker threads are responsible for executing the message handling code for each process. The scheduler determines the order in which processes are passed to the worker threads to handle pending messages.

A principal is shared between one or more processes. The principal is the entity used by the scheduler and message predicates to classify and prioritize a process. Typically the processes that share a principal are in different groups and the principal enables consistent scheduling and admission control policies across groups.

The JVM is capable of supporting an order of magnitude more processes than threads. With appropriate operating system configuration it is not unreasonable for a low end server to support 100s of 1000s of concurrent actors and 10s of 1000s of concurrent connections.

\subsection{Processes}
\label{section:Processes}

Processes are isolated and do not share memory. To communicate with a process a message is posted to the process. The ownership of the message contents is transferred to the receiving process. Message delivery is asynchronous and messages are placed in a process--local queue or inbox. Message transmission is asynchronous to ensure that the sender is isolated from the receiver and the sender can not be blocked, or delayed by a slow receiver. It should be noted that message passing in Whirlwind obeys the \emph{happened--before} ordering of events.

A process is not scheduled unless it has at least one message in it's inbox. A scheduled process dequeues the first message from it's inbox and passes it to the message handling code. On completion of handling the message, control is passed back to the runtime to schedule the next process. The runtime ensures that messages for a single process are handled sequentially. This design eliminates the need for locks.

Handling messages for a process occurs in a FIFO order with the aim of simplifying the logic within each process. This does mean that it is impossible to implement high priority messages or out--of--band messages but this was considered a reasonable trade--off given the decrease in overall system complexity.

The message post operation can fail and raise an exception for the sender to handle. The post operation fails if the receiver process has terminated or if a message predicate rejects the message. The sender is responsible for determining how to respond to the message rejection.

Processes are marked as terminated if the process explicitly invokes the \verb+complete()+ or \verb+fail(Exception e)+ operation or if the process raises an exception during message handling. If the process is terminated via an exception then the process is marked as a \emph{non--normal} termination (a.k.a. a failure) and the exception is recorded. 

To release heavyweight or native resources (i.e. socket descriptors) on process termination, a process can override the \verb+onTerminate(Throwable t)+ method. This method is similar in purpose to the \verb+Object.finalize()+ method except that it is invoked on process termination rather than during garbage collection. 

A process can be monitored by another another process by invoking the \verb+monitor(AbstractProcess other)+. When the process terminates, the runtime sends a termination message to all monitoring processes. If the monitoring process has been configured as a \emph{system} process then the message will be handled in the same manner as other messages. This allows the monitoring process to implement an appropriate error recovery protocol.

A \emph{non--system} process that receives a \emph{non--normal} termination message will fail while normal termination messages will be silently dropped. Typically \emph{non--system} processes will have bidirectional monitoring relationship with all ``peer'' processes that share a common goal so that if one fails, all fail. For example, a HTTP connection may be represented by three or more processes; a process to manage the socket, a process to encode and decode the http protocol and a process to generate the content. If one fails then all should fail and typically the failure will also be propagated to a system process that decides whether further error recovery response is required.

\subsection{Groups}
\label{section:Groups}

Most Internet services support many concurrent requests and many of these requests perform similar computations. Identifying requests that are at a similar stage of processing and executing a ``cohort'' of them sequentially increases code and data locality. This in turn increases performance by reducing cache misses~\cite{Larus:2002:Cohort,welsh03Adaptive}. Groups are designed to identify processes that have a high degree of code and data locality and thus the group defines an ideal ``cohort''.

Groups contain a pool of worker threads. Each thread continuously loops, asking the scheduler for a process that is in the ready state (i.e. the process has messages in it's inbox), locking the process and invoking the message handling code for that process. A cohort is the set of processes that is executed by a single worker thread before the operating system initiates a context switch.

Cohort scheduling has limited effectiveness when the processes perform blocking operations, as the size of the cohort is limited by the number of non--blocking operations that can occur in succession. When it is impossible or impractical to avoid blocking operations, the processes that perform these operations should be placed in a separate group.

Using a pool of worker threads for each group has the advantage that it allows the work for a single group to be distributed over multiple hardware processors. Secondly, if the processes ever perform any blocking operations then it will not block all processes within the group. 

\subsection{Principals}

A principal represents the application entity that is considered a single unit of work (or \emph{transaction}) from the point of view of an external system. Typically the principal is also the unit of load used to measure system performance. An Internet service may represent each ``request'', ``connection'' or ``session'' entity as a single principal.

The principal is associated with all the processes that are responsible for servicing the entity. Often these processes form a single message path. i.e. a HTTP server that uses a ``connection'' principal may associate the principal with the \verb+SocketConnection+, \verb+HttpConnection+ and \verb+PageGenerator+ processes.

The principal is the category that is prioritized during scheduling and load shedding. So all the processes that are servicing a single principal can be consistently prioritized. This avoids the scenario where a high priority process is penalized due to a low priority predecessor or successor process.

The principal abstraction has been used to replicate past work such as session--based admission control~\cite{Cherkasova:2002yb}, request aware scheduling~\cite{Zhou06RequestAware} and class--based differentiation admission control~\cite{welsh03Adaptive}. The principal abstraction has also made it possible to explore the space between the categorization and prioritization of requests and the relationship between scheduling and load shedding.

\subsection{Message Predicates}

A group may define a message predicate that offer a form of per--group admission control. Before a message is delivered to a process within the group, the message predicate may decide to reject a message. A rejected message typically signals that the group is overloaded and that there is insufficient resources to handle the message. This gives the application the chance to perform load shedding and avoid overcommitment of resources.

The post operation will raise an exception when a message is rejected thus allowing the source process the opportunity to attempt alternative action. A HTTP service may first attempt to deliver a media rich page. If this message is rejected, the service attempts to deliver a lower resolution page as presented in Figure~\ref{figure:http-server}(b). This allows the service to deliver progressively lower resolution content as the load on the service increases thus avoiding overload~\cite{abdelzaher99web}. SEDA demonstrated the effectiveness of the message predicate primitive in overload management~\cite{welsh03Adaptive}. 

The simplest predicate rejects messages when the number of un--handled messages within a group exceeds a threshold. More advanced predicates will estimate the cost of handling a message and ensure that the cost of un--handled messages never exceeds a threshold where the threshold is dynamically adjusted based on feedback loops. Other predicates attempt to reject messages with the lowest utility versus cost ratio.

Included with Whirlwind is a library of message predicates that the application user can reuse or extend. In most scenarios, the application specific component (i.e. cost estimation or utility estimation) is easily isolated to a few template methods that can be overridden by application developers. These template methods may appear in the message predicate or more often on the principal and message classes.

\subsection{Schedulers}

Every group defines a scheduler that determines the order in which processes are passed to the worker threads. A process is scheduled when a message is posted to it. The scheduler algorithm can take into account characteristics of the message as well as the principal of the destination process during the scheduling decision.

The default scheduler uses a FIFO algorithm but there are several other schedulers included within the Whirlwind. i.e. A stride scheduler~\cite{Stride:Waldspurger:95} allocates processing proportionally to different request classes. The ability to define custom schedulers has made it possible to replicate past work such as request aware scheduling~\cite{Zhou06RequestAware} and resource aware scheduling~\cite{Behren03Capriccio}.

\subsection{Adaptive Concurrency Level}

The execution of message handling code is driven by a pool of worker threads. The size of the thread pool or the concurrency level has a significant impact on the performance of the system. Too many threads results in thrashing and a decrease in throughput. Too few threads and hardware resources are under utilized, particularly if many threads are blocking or performing long running operations. Not to mention that the underlying operating system typically has hard limits on the number of threads. The ideal concurrency level will vary depending on the current request load, the request distribution and the resources available to the group.

Whirlwind uses adaptive algorithms to adjust the groups concurrency level to maximize throughput. Similar approaches have been proposed for for database systems~\cite{Heiss:91:AdaptiveLoadControl} and other Internet service architectures~\cite{welsh03Adaptive} but as far as we know has never been applied to actor based systems. This is most likely due to the fact that most scalable actor based systems do not allow a blocked actor to consume a thread.

Whirlwind provides several controller implementations that dynamically adjust the concurrency level of a group. Periodically the controller observes performance characteristics and adjusts the pool size in an attempt to meet throughput and response time goals. The developer can also specify a custom controller or use one of the predefined controllers.

\subsection{Libraries}

Included with Whirlwind is a library that includes implementations of runtime components such as schedulers, message predicates, resource controllers and principals. The library also includes reusable slices of applications providing; access to file systems, access to sockets, TLS/SSL translation, HTTP connection management, schedulers, a declarative xml format for assembling and configuring applications etc. There is also a testing and benchmarking framework with a database--backed, web UI for recording and measuring performance of Whirlwind based systems.

The most interesting library included within Whirlwind is the supervisor library. The supervisor library is loosely based on the Erlang implementation of supervisors~\cite{Armstrong03Thesis}. The library includes a system process that will monitor child processes and attempt error recovery if the child processes fail. Several error recovery strategies are provided. 

As in Erlang, the supervisor processes are typically organized into a tree such that all but the root supervisor process is monitored by another supervisor. If a supervisor fails to recover from a child failure then it can in turn fail and force the parent supervisor process to attempt error recovery. For the system to fail, all supervisors in the tree must fail to recover from the error. 

\section{Whirlwind in Practice}

The best way to get a feel for the architecture is to look at the design for a Whirlwind application. This section describes the design of the HTTP server component used in IRIS. Figure~\ref{figure:http-server}(a) presents a basic design of subsystem responsible for processing HTTP connections.

\begin{figure*}[htbp]
\centering
\includegraphics[width=\linewidth]{http-server.eps}
\caption{(a) The subsystem responsible for processing HTTP connections. All of the groups contain processes of a single type except for the ``Resource Handler'' group that includes processes of type ``List'' and ``Show'' for listing a set of resources and presenting detailed information about a single resource respectively. For the sake of simplicity, the message paths are presented as flowing in one direction but all paths are bidirectional except that the handlers that communicate directly with \emph{HttpConnection} processes. (b) The message predicate attached to the \emph{FileHandler} group rejects a message requesting the high quality version of a file but accepts a message requesting a less resource intensive, low quality version of a file.}
\label{figure:http-server}
\end{figure*} 

Each connection to the HTTP server resulted in the creation of three processes; a \verb+SocketConnection+ process to manage the underlying socket, a \verb+HttpConnection+ process to decode and encode HTTP messages and manage the HTTP connection state, and a \verb+Dispatcher+ that routes the HTTP requests to specific handlers based on the contents of the headers, method and uri of the request. Each request submitted to the server results in the \verb+Dispatcher+ creating a \emph{handler} process. A handler is responsible for delivering content from the filesystem or dynamically generating content based based on values retrieved from a database. 

The handler will usually generate one or more processes while handling the request. For example, the \verb+FileHandler+ process creates an \verb+AsyncFile+ process while the \verb+ListResources+ process creates a \verb+DbConnection+ process. Handlers share a group if they utilize similar resources and load shedding treats these handlers similarly. However, most handlers and other other processes in the system will have a single group per process type.

Most Whirlwind applications will only place messages predicates on a few specific groups. The HTTP server defines a message predicate on the \verb+Dispatcher+ group and on each of the handler groups. If a message predicate attached to a handler group rejects a message then the dispatcher may attempt to send a less resource intensive request to the handler, as presented in Figure~\ref{figure:http-server}(b). If the low resolution message is rejected then the \verb+Dispatcher+ returns a ``503 Service Unavailable'' response to the client and closes the connection.

The HTTP server defines a single principal for each HTTP session. When a client accesses a page it is typical that several requests occur over one or more HTTP connections. The requests typically load the HTML page and supporting resources such as images. A message predicate that decides to reject messages should either reject all requests from a session or none at all, as partial loading of a page results in a poor user experience~\cite{Cherkasova:2002yb}. 

The creation of a new handler for every request rather than handler reuse is deliberate. This design results in all the processes in Figure~\ref{figure:http-server} being  associated with a single principal thus allowing consistent treatment by schedulers and message predicates across the whole system.

The prioritization of principals takes into account whether the session is for an authenticated user and if the user is in the \emph{admin} role. Administrators are given the highest priority while unauthenticated users are given the lowest priority.

\section{Evolution of the Framework}

Whirlwind has gone through 5 major revisions. Initially Whirlwind was a shared--memory, event--driven architecture heavily influenced by SEDA~\cite{welsh03Adaptive}. At the end of each fire season, the architecture of Whirlwind was re--evaluated and changes made to avoid problems experienced in the production environment. 

By Whirlwind v4.0 the architecture had evolved to use the actor model of concurrency and had incorporated the Erlang model of fault propagation and recovery. The concurrency and isolation constraints of processes were enforced by a byte code validator not dissimilar to the byte code weaver in Kilim~\cite{Srinivasan:08:Kilim}.

The demands of deploying the code into a production environment where both failures and poor performance were costly drove the framework away from using shared memory. Forcing the process to handle messages sequentially in a FIFO order proved to result in dramatically simplified code for the process, fewer bugs and no measurable performance degradation.

\section{Future Work}

There are two major changes planned for the next version of Whirlwind. The first change is to support Kilim~\cite{Srinivasan:08:Kilim} or Kilim--like processes executing on top of the Whirlwind runtime. The second is to investigate the possibility of dynamically organizing processes into groups at runtime. 

Kilim processes are lightweight threads that use automatic stack management~\cite{Adya02Cooperative} to maintain continuation data between handling messages compared to more complex manual stack management present in Whirlwind processes. Kilim attempts to optimize saving and restoring stack state when a process is paused or resumed. The degree of overhead is related to the number of frames on the stack when the process is paused or resumed. Experience with existing Whirlwind applications suggest that a paused process will only have a small number of active frames. The expectation is that the small performance degradation is an acceptable tradeoff for certain classes of process.

Automatic grouping of processes will reduce the level of complexity for developing Whirlwind based applications. As groups are likely to be created on demand, processes will need to support migration from one group to another. Automatic grouping would also lead to the decoupling of the message predicate from the group. Simple heuristics combined with annotations and runtime instrumentation can automate the organization of processes into groups with manual grouping possible when heuristics perform poorly.

\section{Conclusions}

Whirlwind demonstrates that existing load management techniques can be incorporated into a framework based on the actor model of concurrency. Flexible scheduling policies, cohort scheduling and message predicates proved to be useful additions to the actor runtime. 

The programming model introduces the principal abstraction. The principal centralizes the categorization and prioritization of requests and allows past work in scheduling and load shedding to be examined in a unified framework.

Whirlwind is a synthesis of existing techniques put to the test in a production environment for five years, in a context where there is a high cost for failure or poor performance. Several Whirlwind--based emergency response systems experienced extreme loads as a result of Victoria's worst fire season in 2009. The overload was effectively managed due in part to the infrastructure provided by Whirlwind.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}